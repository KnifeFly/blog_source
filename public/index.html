<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta property="og:type" content="website">
<meta property="og:title" content="KnifeFly">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="KnifeFly">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="KnifeFly">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>KnifeFly</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">KnifeFly</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/17/LSM存储概述/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/17/LSM存储概述/" itemprop="url">Log Structured Merge Trees 概述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-17T13:01:29+08:00">
                2019-10-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="Log-Structured-Merge-Trees-概述"><a href="#Log-Structured-Merge-Trees-概述" class="headerlink" title="Log Structured Merge Trees 概述"></a>Log Structured Merge Trees 概述</h1><p>ClickHouse数据存储原理采用的思想和LSM基本一致，本文主要讲述LSM数据存储的设计思想和基本原理。本文部分内容来自网上一篇译文，原文地址已找不到。</p>
<p>具体十年前，谷歌发表了 BigTable”的论文，提出了一种数据存储的方法叫Log Structured-Merge Tree，简称LSM。现在LSM已被用在许多产品的文件结构策略：HBase、 Cassandra、 LevelDB、RocksDB，包括刚开源不久的ClickHouse数据库的存储引擎也采用的是类似LSM原理。</p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p>简单地说，LSM的设计主要是为了解决随机写的效率问题而采用的顺序写，可大大提升数据读写性能而提出的。当前大家都知道磁盘随机读写速度慢，顺序写可大大提升读写吞吐量。这种采用顺序写而提升系统吞吐量比较出名的开源组件是消息中间件Kafka，Kafka采用offset + 追加写具备很高的读写性能，也是目前大数据平台必备组件之一。</p>
<p>但是对于数据存储系统，采用顺序追加写可解决写性能问题，对于读主要有几种设计方向：</p>
<ol>
<li>二分查找：将文件数据有序保存，使用二分查找来完成特定key的查找。</li>
<li>哈希：用哈希将数据分割为不同的bucket</li>
<li>B+树：使用B+树 或者 ISAM 等方法，可以减少外部文件的读取</li>
<li>外部文件： 将数据保存为日志，并创建一个hash或者查找树映射相应的文件。</li>
</ol>
<p>所有的方法都可以有效的提高了读操作的性能（最少提供了O(log(n)) )，但是，却丢失了日志的写性能。上面这些方法，都强加了总体的结构信息在数据上，数据被按照特定的方式放置，所以可以很快的找到特定的数据，但是却对写操作不友善，让写操作性能下降。更糟糕的是，当我们需要更新hash或者B+树的结构时，需要同时更新文件系统中特定的部分，这就是上面说的比较慢的随机读写操作。<strong>这种随机的操作要尽量减少</strong>。</p>
<p>所以这就是 LSM 被设计的原因， LSM 使用一种不同于上述四种的方法，保持了日志文件写性能，以及微小的读操作性能损失。本质上就是让所有的操作顺序化，而不是像散弹枪一样随机读写。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/10/17/LSM存储概述/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/15/go 性能调优/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/15/go 性能调优/" itemprop="url">golang 性能调优</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-15T21:18:39+08:00">
                2019-10-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="优化前提"><a href="#优化前提" class="headerlink" title="优化前提"></a>优化前提</h2><ul>
<li><p>基础功能</p>
</li>
<li><p>架构设计</p>
</li>
<li><p>硬件资源</p>
</li>
</ul>
<h2 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h2><p>​    思想同c/c++系统优化基本相同</p>
<ul>
<li><p>CPU密集型/IO密集型</p>
<p>先分析程序是属于CPU密集型还是IO密集，如果是IO密集型，数据读写是否可使用内存盘、固态盘? 如果是CPU密集型，单线程程序是否可以改造成多线程?  多线程是否存在抢锁，或者同步?  是否可以减小锁粒度设置实现无锁设计</p>
</li>
<li><p>函数高频调用</p>
<p>高频调用的函数性能能有所提升，基本上可直接提升程序的整体性能</p>
</li>
<li><p>锁粒度</p>
<p>对于高性能计算程序，最好不要设计多线程抢锁的程序架构，如果锁设计不可避免那是否可以优化到减小锁粒度? </p>
</li>
<li><p>线程池/协程池</p>
<p>如果程序中存在大量创建线程的情况，可加一个线程池，减小创建线程的消耗在一定程序上可提高系统吞吐量。在Go中虽然创建协程开销很小，但是系统创建大量程序可能奔溃</p>
</li>
<li><p>对象池</p>
<p>如果程序中不可避免的创建大量小对象，可用对象池来减小GC压力，类似内存池</p>
</li>
</ul>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/10/15/go 性能调优/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/04/ClickHoue 表引擎概述/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/04/ClickHoue 表引擎概述/" itemprop="url">ClickHouse 表引擎概述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-04T12:01:29+08:00">
                2019-10-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="ClickHouse-引擎"><a href="#ClickHouse-引擎" class="headerlink" title="ClickHouse 引擎"></a>ClickHouse 引擎</h2><p>Clickhouse 提供了丰富的存储引擎，存储引擎的类型决定了数据如何存放、如何做备份、如何被检索、是否使用索引。不同的存储引擎在数据写入/检索方面做平衡，以满足不同业务需求。</p>
<p>Clickhouse 提供了十多种引擎，主要是用的是<code>MergeTree</code>  系表引擎。</p>
<h3 id="TinyLog"><a href="#TinyLog" class="headerlink" title="TinyLog"></a>TinyLog</h3><p>这是最简单的表引擎，它将数据存储在磁盘上。每列都存储在一个单独的压缩文件中。写入时，数据被附加到文件的末尾。该类型引擎不支持索引 这种引擎没有并发数据访问控制：</p>
<ul>
<li>同时对一张表进行读写操作，读操会错误</li>
<li>同时在多个查询中进行写入操作，数据将被破坏</li>
</ul>
<p>使用此表的典型方法是一次写入：只需要一次写入数据，然后根据需要多次读取它。查询在单个流处理中执行，换句话说该引擎适用于相对较小的表格（官方推荐建议一百万行以内）。如果你有很多小表，使用这个表引擎是很有意义的，因为他比Log Engines（另一个引擎下边会介绍）更简单（需要代开的文件更少）。当你有大量读写效率很低的小表时，而且在与另一个DBMS一起工作时已经被使用了，你可能会发现切换到使用TinyLog类型的表更容易。 在Yandex.Metrica中，TinyLog表用于小批量处理的中间数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE test.tinyLog_test ( id String,  name String) ENGINE = TinyLog</span><br><span class="line"></span><br><span class="line">insert into test.Log_test (id, name) values (&apos;1&apos;, &apos;first&apos;);</span><br></pre></td></tr></table></figure>
<p>找到数据目录（{home}/clickhouse/data/data/test）数据在磁盘上的结构如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@root test]$ tree  -CL 5 ./tinyLog_test/</span><br><span class="line">./tinyLog_test/</span><br><span class="line">├── id.bin</span><br><span class="line">├── name.bin</span><br><span class="line">└── sizes.json</span><br></pre></td></tr></table></figure>
<p>a.bin 和 b.bin 是压缩过的对应的列的数据， sizes.json 中记录了每个 *.bin 文件的大小：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@root test]$ cat ./tinyLog_test/sizes.json </span><br><span class="line">&#123;&quot;yandex&quot;:&#123;&quot;id%2Ebin&quot;:&#123;&quot;size&quot;:&quot;28&quot;&#125;,&quot;name%2Ebin&quot;:&#123;&quot;size&quot;:&quot;32&quot;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/10/04/ClickHoue 表引擎概述/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/03/TCMalloc 简介/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/03/TCMalloc 简介/" itemprop="url">TCMalloc 简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-03T11:05:29+08:00">
                2019-10-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="TCMalloc"><a href="#TCMalloc" class="headerlink" title="TCMalloc"></a>TCMalloc</h1><p>TCMalloc 是Google推出的内存管理库，比较常见的内存池库还有ptmalloc和jemalloc，相比后两者tcmalloc性能更改好，更适用于多线程高并发的场景。Golang 内存管理采用的方法和TCMalloc有点类似。</p>
<p>相比glibc maclloc，tcmalloc更快，根据官方提供的数据，glibc 2.3 malloc在同样的机器上maclloc/free大于需要300纳秒，tcmaclloc的实现只要50纳秒，两者相比差异还是挺大。所以开发者通常会基于glibc malloc峰值一个内存池，程序在启动的时候先向系统申请一大块内存，然后再把申请的大块内存划分为多个空闲列表。tcmalloc就是一个实现了这样的内存管理库。</p>
<p>简单来说，TCMalloc内存分配策略采用分级策略，一个是线程私有内存池，另一个是全局内存池。对于一些小内存的分配则直接在线程私有内存池中分配，无需加锁，大大地减小内存分配锁竞争，只有在线程私有内存不够时则从全局内存池分配。对于大容量的内存分配则直接从全局内存池中分配，这个时候则需要加锁。内存池的组织形式采用数组 + 链表的方式，数组的每个元素是一个链表，链表中每个元素大小则相同。</p>
<p>TCMalloc为每个线程分配一个线程本地缓存。线程本地缓存满足小分配。根据需要将对象从中央数据结构移动到线程本地缓存中，并使用定期垃圾回收将内存从线程本地缓存迁移回中心数据结构中</p>
<p>TCMalloc将大小小于等于32K的对象（“小”对象）与大对象区别对待。使用页面级分配器（页面是内存的4K对齐区域）直接从中央堆分配大对象。即，大对象始终是页面对齐的，并且占据整数页。</p>
<p><img src="../images/tcmalloc_overview.gif" alt="tcmalloc总览"></p>
<h2 id="小对象分配"><a href="#小对象分配" class="headerlink" title="小对象分配"></a>小对象分配</h2><p>每个线程会包含一个数组链表，同一个链表中拥有相同大小的空闲对象。</p>
<p>当分配一个小对象时，主要分配的步骤如下：</p>
<ul>
<li>根据要分配对象的大小，映射到相应的大小类</li>
<li>在线程私有内存池中相应大小类的空闲链表</li>
<li>如果空闲链表不为空，则返回第一个空闲对象，不需要加锁</li>
<li>如果空闲链表为空，则需要从全局内存池中获取空闲对象</li>
</ul>
<p><img src="../images/tcmalloc_threadheap.gif" alt="tcmalloc总览"></p>
<h2 id="大对象分配"><a href="#大对象分配" class="headerlink" title="大对象分配"></a>大对象分配</h2><p>对于大于32K的大对象分配则由全局内存来分配。全局内存的组织也是单链表数组，数组长度为256，分别对用1 page大小, 2 page大小(1 page=4k)</p>
<p><img src="../images/tcmalloc_pageheap.gif" alt="tcmalloc总览"></p>
<p>参考文档：</p>
<ol>
<li><a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html" target="_blank" rel="noopener">官网文档</a></li>
<li><a href="http://legendtkl.com/2015/12/11/go-memory/#comments" target="_blank" rel="noopener">http://legendtkl.com/2015/12/11/go-memory/#comments</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/15/Kafka高性能架构之道/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/15/Kafka高性能架构之道/" itemprop="url">Kafka高性能架构之道</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-15T11:21:49+08:00">
                2019-09-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="Kafka高性能架构之道"><a href="#Kafka高性能架构之道" class="headerlink" title="Kafka高性能架构之道"></a>Kafka高性能架构之道</h2><p>本文转发自<a href="http://www.jasongj.com/" target="_blank" rel="noopener"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/kafka/high_throughput/" target="_blank" rel="noopener">原文链接</a></p>
<p>本文从宏观架构层面和微观实现层面分析了Kafka如何实现高性能。包含Kafka如何利用Partition实现并行处理和提供水平扩展能力，如何通过ISR实现可用性和数据一致性的动态平衡，如何使用NIO和Linux的sendfile实现零拷贝以及如何通过顺序读写和数据压缩实现磁盘的高效利用。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><h1 id="宏观架构层面"><a href="#宏观架构层面" class="headerlink" title="宏观架构层面"></a>宏观架构层面</h1><h2 id="利用Partition实现并行处理"><a href="#利用Partition实现并行处理" class="headerlink" title="利用Partition实现并行处理"></a>利用Partition实现并行处理</h2><h3 id="Partition提供并行处理的能力"><a href="#Partition提供并行处理的能力" class="headerlink" title="Partition提供并行处理的能力"></a>Partition提供并行处理的能力</h3><p>Kafka是一个Pub-Sub的消息系统，无论是发布还是订阅，都须指定Topic。如《<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1" target="_blank" rel="noopener">Kafka设计解析（一）- Kafka背景及架构介绍</a>》一文所述，Topic只是一个逻辑的概念。每个Topic都包含一个或多个Partition，不同Partition可位于不同节点。同时Partition在物理上对应一个本地文件夹，每个Partition包含一个或多个Segment，每个Segment包含一个数据文件和一个与之对应的索引文件。在逻辑上，可以把一个Partition当作一个非常长的数组，可通过这个“数组”的索引（offset）去访问其数据。</p>
<p>一方面，由于不同Partition可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于Partition在物理上对应一个文件夹，即使多个Partition位于同一个节点，也可通过配置让同一节点上的不同Partition置于不同的disk drive上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p>
<p>利用多磁盘的具体方法是，将不同磁盘mount到不同目录，然后在server.properties中，将<code>log.dirs</code>设置为多目录（用逗号分隔）。Kafka会自动将所有Partition尽可能均匀分配到不同目录也即不同目录（也即不同disk）上。</p>
<p>注：虽然物理上最小单位是Segment，但Kafka并不提供同一Partition内不同Segment间的并行处理。因为对于写而言，每次只会写Partition内的一个Segment，而对于读而言，也只会顺序读取同一Partition内的不同Segment。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/09/15/Kafka高性能架构之道/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/25/ClickHouse压缩与解压/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/25/ClickHouse压缩与解压/" itemprop="url">ClickHouse 数据压缩与解压</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-25T12:43:29+08:00">
                2019-08-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ClickHouse-数据压缩与解压"><a href="#ClickHouse-数据压缩与解压" class="headerlink" title="ClickHouse 数据压缩与解压"></a>ClickHouse 数据压缩与解压</h1><p>ClickHouse 是一款真正面向列的DBMS，就是一款列式数据库，所以ClickHouse非常适合作为OLAP的数据查询引擎。通常列式数据库具有非常好的数据压缩效果，因为每列数据的数据类型一致，保存时会作为一个数组数据挨着保存，这样压缩算法具有非常好的压缩效果，在OLAP查询场景下可以有效的提高整个系统的吞吐量。</p>
<p>ClickHouse目前支持的数据压缩算法是lz4和zstd，其中zstd是实验性，默认情况下ClickHouse采用的是lz4压缩算法。压缩的主要配置项示例如下，通常情况下不会去更改这几个配置项，因为默认配置就可以让数据压缩效率非常高。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">compression</span> <span class="attr">incl</span>=<span class="string">"clickhouse_compression"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">case</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">min_part_size</span>&gt;</span>10000000000<span class="tag">&lt;/<span class="name">min_part_size</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">min_part_size_ratio</span>&gt;</span>0.01<span class="tag">&lt;/<span class="name">min_part_size_ratio</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">method</span>&gt;</span>zstd<span class="tag">&lt;/<span class="name">method</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">case</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">compression</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>关于压缩算法的测试，见<a href="https://link.zhihu.com/?target=https%3A//www.percona.com/blog/2016/04/13/evaluating-database-compression-methods-update/" target="_blank" rel="noopener">这篇文章</a>。简而言之，LZ4在速度上会更快，但是压缩率较低，ZSTD正好相反。尽管ZSTD比LZ4慢，但是相比传统的压缩方式Zlib，无论是在压缩效率还是速度上，都可以作为Zlib的替代品。</p>
<h2 id="压缩比"><a href="#压缩比" class="headerlink" title="压缩比"></a>压缩比</h2><p>官方有提供星型模块基准测试的案例，<a href="https://www.altinity.com/blog/2017/6/16/clickhouse-in-a-general-analytical-workload-based-on-star-schema-benchmark" target="_blank" rel="noopener">clickhouse-in-a-general-analytical-workload-based-on-star-schema-benchmark</a>  该基准测试案例lineorder数据表字段基本都是整形，该表lineorder原始数据有150亿条记录，原始数据总大小为1.7TB，导入到ClickHouse后lineorder数据表占用464GB，压缩比达到了3.7倍数。</p>
<p>目前我们的ClickHouse数据库中存储一些nginx原始日志信息raw_cdn_nginx_log_all，nginx原始访问日志以及维度扩展之后的日志数据每行大概会有100左右个字段信息，我们截取其中40多个有助于OLAP查询高频字段，数据表字段信息：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">(</span><br><span class="line">    timeStamp DateTime,</span><br><span class="line">    date Date,</span><br><span class="line">    province String,</span><br><span class="line">    isp String,</span><br><span class="line">    upstream_addr String,</span><br><span class="line">    hostname String,</span><br><span class="line">    machineIP String,</span><br><span class="line">    country String,</span><br><span class="line">    scheme String,</span><br><span class="line">    upstream_local_port String,</span><br><span class="line">    channel String,</span><br><span class="line">    node String,</span><br><span class="line">    cacheGroup String,</span><br><span class="line">    city String,</span><br><span class="line">    view String,</span><br><span class="line">    status String,</span><br><span class="line">    customer String,</span><br><span class="line">    nodeisp String,</span><br><span class="line">    app String,</span><br><span class="line">    http_host String,</span><br><span class="line">    upstream_status String,</span><br><span class="line">    deviceID String,</span><br><span class="line">    remote_addr String,</span><br><span class="line">    request_id String,</span><br><span class="line">    serviceGroupId String,</span><br><span class="line">    request String,</span><br><span class="line">    http_referer String,</span><br><span class="line">    serverType String,</span><br><span class="line">    conn_state String,</span><br><span class="line">    upstream_keepalive String,</span><br><span class="line">    http_user_agent String,</span><br><span class="line">    body_bytes_sent Int64,</span><br><span class="line">    client_rtt Float32,</span><br><span class="line">    ssl_handshake_time Float32,</span><br><span class="line">    response_time Float32,</span><br><span class="line">    first_byte_time Float32,</span><br><span class="line">    upstream_response_time String,</span><br><span class="line">    bytes_sent Int64,</span><br><span class="line">    download_time Float32,</span><br><span class="line">    half_rtt_time Float32,</span><br><span class="line">    request_time Float32</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>ClickHouse集群有4台机器，2019-06-14这一天集群的数据记录条数是2.4亿，那时候还不算业务爆发期，这2.4亿条的数据在clickhouse集群中总占用大小在12G左右，每台机器占用空间大小为3G左右。</p>
<p><img src="/images/image-20190825110851852.png" alt="sd"></p>
<p>每行原始数据信息大概如下，每条JSON格式的数据记录大概是1000字节左右，2.4亿条JSON格式的输入数据大小为240G左右。如果是以CSV格式存储，则单条记录大小大概是380字节，2.4亿条CSV格式的输入数据大小为93G。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"timeStamp"</span>:<span class="string">"2019-06-14 02:37:31"</span>,<span class="attr">"date"</span>:<span class="string">"2019-06-14"</span>,<span class="attr">"province"</span>:<span class="string">"GZ"</span>,<span class="attr">"isp"</span>:<span class="string">"CM"</span>,<span class="attr">"upstream_addr"</span>:<span class="string">""</span>,<span class="attr">"hostname"</span>:<span class="string">"SR-CNCM-GZKWE-38-23"</span>,<span class="attr">"machineIP"</span>:<span class="string">"xxx"</span>,<span class="attr">"country"</span>:<span class="string">"CN"</span>,<span class="attr">"scheme"</span>:<span class="string">"https"</span>,<span class="attr">"upstream_local_port"</span>:<span class="string">""</span>,<span class="attr">"channel"</span>:<span class="string">"xxx"</span>,<span class="attr">"node"</span>:<span class="string">"IDC-CNCM-GZKWE-Dnion"</span>,<span class="attr">"cacheGroup"</span>:<span class="string">"SG-CNCM-GZKWE-cacheOpt-01"</span>,<span class="attr">"city"</span>:<span class="string">"KWE"</span>,<span class="attr">"view"</span>:<span class="string">"CN_CM_XN_GZ"</span>,<span class="attr">"status"</span>:<span class="string">"200"</span>,<span class="attr">"customer"</span>:<span class="string">"meitu"</span>,<span class="attr">"nodeisp"</span>:<span class="string">"CM"</span>,<span class="attr">"app"</span>:<span class="string">"APP-WEB"</span>,<span class="attr">"http_host"</span>:<span class="string">"api.meipai.com"</span>,<span class="attr">"upstream_status"</span>:<span class="string">"200"</span>,<span class="attr">"deviceID"</span>:<span class="string">"9233d8bbfe37eed97679b6f768858d06"</span>,<span class="attr">"remote_addr"</span>:<span class="string">"223.104.96.19"</span>,<span class="attr">"request_id"</span>:<span class="string">"31f80ef11dc338493cf25c5334dcbfc8"</span>,<span class="attr">"serviceGroupId"</span>:<span class="string">"1152"</span>,<span class="attr">"request"</span>:<span class="string">""</span>,<span class="attr">"http_referer"</span>:<span class="string">""</span>,<span class="attr">"serverType"</span>:<span class="string">"0"</span>,<span class="attr">"conn_state"</span>:<span class="string">""</span>,<span class="attr">"upstream_keepalive"</span>:<span class="string">"1"</span>,<span class="attr">"http_user_agent"</span>:<span class="string">""</span>,<span class="attr">"body_bytes_sent"</span>:<span class="string">"8069"</span>,<span class="attr">"client_rtt"</span>:<span class="number">0.029</span>,<span class="attr">"ssl_handshake_time"</span>:<span class="number">0</span>,<span class="attr">"response_time"</span>:<span class="number">0.259</span>,<span class="attr">"first_byte_time"</span>:<span class="number">-0</span>,<span class="attr">"upstream_response_time"</span>:<span class="string">"0.258"</span>,<span class="attr">"bytes_sent"</span>:<span class="string">"8364"</span>,<span class="attr">"download_time"</span>:<span class="number">-0</span>,<span class="attr">"half_rtt_time"</span>:<span class="number">2685.709</span>,<span class="attr">"request_time"</span>:<span class="number">0.259</span>&#125;</span><br></pre></td></tr></table></figure>
<p>总结：2.4亿条原始nginx日志，原始JSON格式数据大小240G，CSV格式的数据大小为93G，存储到ClickHouse后占用磁盘大小12G左右。不管以哪种方式存储，ClickHouse具体非常好的数据压缩比。目前线上是从kafka消费JSON格式数据入库到ClickHouse。如果数据表字段少一点或者是数据都存储在一台机器上，ClickHouse压缩比会更高。<a href="https://zhuanlan.zhihu.com/p/32662689" target="_blank" rel="noopener">ClickHouse数据压缩</a>这篇文章有测试过1亿条数据记录ES存储磁盘占用33GB，ClickHouse磁盘占用1.4GB。</p>
<h2 id="ClickHouse解压缩"><a href="#ClickHouse解压缩" class="headerlink" title="ClickHouse解压缩"></a>ClickHouse解压缩</h2><p>当我们在查询ClickHouse数据库数据时，如果采用perf工具对ClickHouse进程采样，会发现LZ_decompress_fast方法占用的CPU时间最多。</p>
<p><img src="/images/057302aba5041790af404c2c781c4dd3.png" alt="sd"></p>
<p>ClickHouse数据以压缩的形式存储在本地磁盘中，当数据查询时ClickHouse为了减少CPU使用资源会尽量少做一些事情。在许多情况下，所有潜在的耗时计算都已经得到了很好的优化，而且用户编写了一个经过深思熟虑的查询，那么剩下要做的就是执行解压缩。</p>
<p>那么为什么LZ4解压缩成为一个瓶颈呢？<a href="https://github.com/lz4/lz4/" target="_blank" rel="noopener">LZ4</a>看起来是一种非常轻的算法:数据解压缩速率通常是每个处理器内核1到3 GB/s，具体取决于数据。这比典型的磁盘子系统快得多。此外，我们使用所有可用的中央处理器内核，解压缩在所有物理内核之间线性扩展。</p>
<p>首先，如果数据压缩率很高，则磁盘上数据占用空间就很小，在读取数据时磁盘IO会比较低，但是如果待解压的数据量很大则会影响到CPU使用率。在LZ4的情况下，解压缩数据所需的工作量几乎与解压缩数据本身的量成正比；其次，如果数据被缓存，你可能根本不需要从磁盘读取数据。可以依赖页面缓存或使用自己的缓存。缓存在面向列的数据库中更有效，因为只有经常使用的列保留在缓存中。这就是为什么LZ4经常成为CPU负载的瓶颈。</p>
<p>在官方的这篇博客中<a href="https://habr.com/en/company/yandex/blog/457612/" target="_blank" rel="noopener">How to speed up LZ4 decompression in ClickHouse</a>，作者反馈有人希望ClickHoouse不要以数据压缩的方式存储数据，因为反馈者认为数据查询时是因为数据解压拖慢了整个查询进度，并且这个人还在github上提了一个<a href="https://github.com/yandex/ClickHouse/pull/1045" target="_blank" rel="noopener">PR</a>，最后维护者觉得<code>Ok. If you are not going to use this compression method, it&#39;s not worth to implement.</code>。</p>
<p>如果可以使用缓存，为何ClickHouse不把解压后的数据存在缓存中呢，这样可以减少很多数据解压的场景，ClickHouse也提供了cache配置项<a href="https://clickhouse.yandex/docs/en/operations/settings/settings/#use_uncompressed_cache" target="_blank" rel="noopener">the cache of decompressed blocks</a>。在博客中作者认为这种方式对内存是极大的浪费，并且只有在查询数据量很小的场景下是有用的。我个人也觉得如果缓存住解压后的数据，ClickHouse进程肯定会经常发生OOM。ClickHouse高效的数据压缩设计其实是一个很好的设计方案，首先可以减小磁盘的数据占用；其次在shard的replica副本个数超过1时，replica之间的数据同步也可以更高效。</p>
<p>目前在生产环境中，ClickHouse简单数据查询P99的时间还是在秒级返回，只有在复杂的数据查询场景下查询时间会增加到几秒，例如多个表join，其实在这个场景下更多的做法应该是优化SQL查询语句，尽量避免大量表join查询。</p>
<p><a href="https://habr.com/en/company/yandex/blog/457612/" target="_blank" rel="noopener">How to speed up LZ4 decompression in ClickHouse</a>这篇官方博客中作者还提到了LZ4是如何工作的以及数据解压缩的优化手段。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/24/压缩算法概览/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/24/压缩算法概览/" itemprop="url">压缩算法概览</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-24T14:21:29+08:00">
                2019-08-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="压缩算法概览"><a href="#压缩算法概览" class="headerlink" title="压缩算法概览"></a>压缩算法概览</h1><blockquote>
<p>压缩的理论（它与<a href="https://zh.wikipedia.org/wiki/算法信息论" target="_blank" rel="noopener">算法信息论</a>密切相关）以及<a href="https://zh.wikipedia.org/wiki/率失真理论" target="_blank" rel="noopener">率有损理论</a>，这个领域的研究工作主要是由美国学者<a href="https://zh.wikipedia.org/wiki/克劳德·香农" target="_blank" rel="noopener">克劳德·香农</a>（Claude Elwood Shannon）奠定的，他在二十世纪四十年代末期及五十年代早期发表了这方面的基础性的论文。</p>
<p>Lempel-Ziv（LZ）压缩方法是最流行的无损存储算法之一。<a href="https://zh.wikipedia.org/wiki/DEFLATE" target="_blank" rel="noopener">DEFLATE</a>是LZ的一个变体，它针对解压速度与压缩率进行了优化，虽然它的压缩速度可能非常缓慢，<a href="https://zh.wikipedia.org/w/index.php?title=PKZIP&amp;action=edit&amp;redlink=1" target="_blank" rel="noopener">PKZIP</a>、<a href="https://zh.wikipedia.org/wiki/Gzip" target="_blank" rel="noopener">gzip</a>以及<a href="https://zh.wikipedia.org/wiki/PNG" target="_blank" rel="noopener">PNG</a>都在使用DEFLATE。<a href="https://zh.wikipedia.org/wiki/LZW" target="_blank" rel="noopener">LZW</a>（Lempel-Ziv-Welch）是<a href="https://zh.wikipedia.org/wiki/Unisys" target="_blank" rel="noopener">Unisys</a>的<a href="https://zh.wikipedia.org/wiki/专利" target="_blank" rel="noopener">专利</a>，直到2003年6月专利到期限，这种方法用于<a href="https://zh.wikipedia.org/wiki/GIF" target="_blank" rel="noopener">GIF</a>图像。另外值得一提的是LZR （LZ-Renau） 方法，它是Zip方法的基础。LZ方法使用基于表格的压缩模型，其中表格中的条目用重复的数据串替换。对于大多数的LZ方法来说，这个表格是从最初的输入数据动态生成的。这个表格经常采用<a href="https://zh.wikipedia.org/wiki/霍夫曼编码" target="_blank" rel="noopener">霍夫曼编码</a>维护（例如SHRI、LZX）。 当前一个性能良好基于LZ的编码机制是<a href="https://zh.wikipedia.org/w/index.php?title=LZX_(algorithm" target="_blank" rel="noopener">LZX</a>&amp;action=edit&amp;redlink=1)，它用于微软公司的<a href="https://zh.wikipedia.org/wiki/CAB" target="_blank" rel="noopener">CAB</a>格式。</p>
</blockquote>
<p>压缩算法分为两个层面：</p>
<ol>
<li>熵编码：根据消息中每个符号出现的概率，然后通过某种映射用更短的符号替代原来的符号，核心在于提高符号的信息熵，哈夫曼编码最为典型。</li>
<li>字典编码：提取信息中的重复部分作为字典，然后通过字典和某种映射替代这些重复的部分，核心在于替代重复，LZ77和LZ78算法最为典型。</li>
</ol>
<h1 id="gzip"><a href="#gzip" class="headerlink" title="gzip"></a>gzip</h1><p><strong>Gzip</strong>是若干种<a href="https://zh.wikipedia.org/wiki/文件压缩" target="_blank" rel="noopener">文件压缩</a><a href="https://zh.wikipedia.org/wiki/程序" target="_blank" rel="noopener">程序</a>的简称，通常指<a href="https://zh.wikipedia.org/wiki/GNU計劃" target="_blank" rel="noopener">GNU计划</a>的实现，gzip的基础是<a href="https://zh.wikipedia.org/wiki/DEFLATE" target="_blank" rel="noopener">DEFLATE</a>，DEFLATE是<a href="https://zh.wikipedia.org/wiki/LZ77与LZ78" target="_blank" rel="noopener">LZ77</a>与<a href="https://zh.wikipedia.org/wiki/哈夫曼编码" target="_blank" rel="noopener">哈夫曼编码</a>的一个组合体。Gzip编码格式在<a href="https://link.juejin.im/?target=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc1952" target="_blank" rel="noopener">RFC 1952</a>中定义。</p>
<p>Gzip亚搜文件格式如下为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| ID1 | ID2 | CM | FLG | MTIME（4字节） | XFL | OS | ---&gt; more</span><br></pre></td></tr></table></figure>
<p>在Centos操作系统中空Gzip文件文件大小为26字节，用二进制查看工具查看文件内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0000000 8b1f 0808 c8fb 5d60 0300 6568 6c6c 006f</span><br><span class="line">0000020 0003 0000 0000 0000 0000</span><br><span class="line">0000032</span><br></pre></td></tr></table></figure>
<ul>
<li>其中 ID1 和 ID2 分别是 0x1f 和 0x8b，用来标识文件格式是 gzip</li>
<li>CM 标识 加密算法，目前 0-7是保留字，8 指的是 <a href="https://link.juejin.im/?target=https%3A%2F%2Fzh.wikipedia.org%2Fwiki%2FDEFLATE" target="_blank" rel="noopener">deflate 算法</a></li>
<li>FLG标志位</li>
<li>MTIME 指的是源文件最近一次修改时间，存的是 Unix 时间戳</li>
<li>XFL defalte 算法中 2 表示使用压缩率最高的算法，4 表示使用压缩速度最快的算法</li>
<li>OS 标识压缩程序运行的文件系统，以处理 EOF 等的问题</li>
<li>more 后面是根据 FLG 的开启情况决定的，可能会有 循环冗余校验码、源文件长度、附加信息等多种其他信息</li>
</ul>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/08/24/压缩算法概览/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/24/ClickHouse运营总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/24/ClickHouse运营总结/" itemprop="url">ClickHouse 运营总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-24T11:37:28+08:00">
                2019-08-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="ClickHouse-运营总结"><a href="#ClickHouse-运营总结" class="headerlink" title="ClickHouse 运营总结"></a>ClickHouse 运营总结</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ClickHouse 是俄罗斯 Yandex 公司所开源的一款用于大数据实时分析的列式数据库管理系统，采用 C++ 编写，对于百亿级数据的查询聚合能达到秒级返回。</p>
<p>ClickHouse 的主要优点有：</p>
<ol>
<li>为了高效的使用CPU，数据不仅仅按列存储，同时还按向量进行处理；</li>
<li>数据压缩空间大，减少io；处理单查询高吞吐量每台服务器每秒最多数十亿行；</li>
<li>索引非B树结构，不需要满足最左原则；只要过滤条件在索引列中包含即可；即使在使用的数据不在索引中，由于各种并行处理机制ClickHouse全表扫描的速度也很快；</li>
<li>写入速度非常快，50-200M/s，对于大量的数据更新非常适用。</li>
</ol>
<p>而为了达到“快”的效果，ClickHouse 付出了如下的代价：</p>
<ol>
<li>不支持事务，不支持真正的删除/更新；</li>
<li>不支持高并发，官方建议 QPS 为100，可以通过修改配置文件增加连接数，但是在服务器足够好的情况下；</li>
<li>SQL 满足日常使用80%以上的语法，join 写法比较特殊；最新版已支持类似 SQL 的 join，但性能不好；</li>
<li>尽量做1000条以上批量的写入，避免逐行 insert 或小批量的 insert，update，delete 操作，因为 ClickHouse 底层会不断的做异步的数据合并，会影响查询性能，这个在做实时数据写入的时候要尽量避开；</li>
<li>ClickHouse 快是因为采用了并行处理机制，即使一个查询，也会用服务器一半的cpu去执行，所以 ClickHouse 不能支持高并发的使用场景，默认单查询使用cpu核数为服务器核数的一半，安装时会自动识别服务器核数，可以通过配置文件修改该参数。</li>
</ol>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/08/24/ClickHouse运营总结/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/15/Spark 内存管理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/15/Spark 内存管理/" itemprop="url">Spark 内存管理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-15T20:01:29+08:00">
                2019-07-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p><a href="https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/index.html" target="_blank" rel="noopener">原文地址</a></p>
<p>Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文旨在梳理出 Spark 内存管理的脉络，抛砖引玉，引出读者对这个话题的深入探讨。本文中阐述的原理基于 Spark 2.1 版本，阅读本文需要读者有一定的 Spark 和 Java 基础，了解 RDD、Shuffle、JVM 等相关概念。</p>
<p>在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能[1]。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。</p>
<h2 id="1-堆内和堆外内存规划"><a href="#1-堆内和堆外内存规划" class="headerlink" title="1. 堆内和堆外内存规划"></a>1. 堆内和堆外内存规划</h2><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。</p>
<h5 id="图-1-堆内和堆外内存示意图"><a href="#图-1-堆内和堆外内存示意图" class="headerlink" title="图 1 . 堆内和堆外内存示意图"></a>图 1 . 堆内和堆外内存示意图</h5><p><img src="https://www.ibm.com/developerworks/cn/analytics/library/ba-cn-apache-spark-memory-management/image001.png" alt="img"></p>
<h3 id="1-1-堆内内存"><a href="#1-1-堆内内存" class="headerlink" title="1.1 堆内内存"></a>1.1 堆内内存</h3><p>堆内内存的大小，由 Spark 应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。</p>
<p>Spark 对堆内内存的管理是一种逻辑上的”规划式”的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前<strong>记录</strong>这些内存，我们来看其具体流程：</p>
<ul>
<li><strong>申请内存</strong>：</li>
</ul>
<ol>
<li>Spark 在代码中 new 一个对象实例</li>
<li>JVM 从堆内内存分配空间，创建对象并返回对象引用</li>
<li>Spark 保存该对象的引用，记录该对象占用的内存</li>
</ol>
<ul>
<li><strong>释放内存</strong>：</li>
</ul>
<ol>
<li>Spark 记录该对象释放的内存，删除该对象的引用</li>
<li>等待 JVM 的垃圾回收机制释放该对象占用的堆内内存</li>
</ol>
<p>我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行序列化的逆过程——反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。</p>
<p>对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期[2]。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。</p>
<p>虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。</p>
<h3 id="1-2-堆外内存"><a href="#1-2-堆外内存" class="headerlink" title="1.2 堆外内存"></a>1.2 堆外内存</h3><p>为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现[3]），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。</p>
<p>在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。</p>
<h3 id="1-3-内存管理接口"><a href="#1-3-内存管理接口" class="headerlink" title="1.3 内存管理接口"></a>1.3 内存管理接口</h3><p>Spark 为存储内存和执行内存的管理提供了统一的接口——MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存:</p>
<h4 id="清单-1-内存管理接口的主要方法"><a href="#清单-1-内存管理接口的主要方法" class="headerlink" title="清单 1 . 内存管理接口的主要方法"></a>清单 1 . 内存管理接口的主要方法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//申请存储内存``def acquireStorageMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode): Boolean``//申请展开内存``def acquireUnrollMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode): Boolean``//申请执行内存``def acquireExecutionMemory(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode): Long``//释放存储内存``def releaseStorageMemory(numBytes: Long, memoryMode: MemoryMode): Unit``//释放执行内存``def releaseExecutionMemory(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode): Unit``//释放展开内存``def releaseUnrollMemory(numBytes: Long, memoryMode: MemoryMode): Unit</span><br></pre></td></tr></table></figure>
<p>我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。</p>
<p>MemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（<a href="https://github.com/apache/spark/blob/v2.1.0/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala" target="_blank" rel="noopener">Unified Memory Manager</a>）方式，1.6 之前采用的静态管理（<a href="https://github.com/apache/spark/blob/v2.1.0/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala" target="_blank" rel="noopener">Static Memory Manager</a>）方式仍被保留，可通过配置 spark.memory.useLegacyMode 参数启用。两种方式的区别在于对空间分配的方式，下面的第 2 小节会分别对这两种方式进行介绍。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/07/15/Spark 内存管理/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/15/ClickHouse zk依赖优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yujie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KnifeFly">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/15/ClickHouse zk依赖优化/" itemprop="url">ClickHouse zk依赖优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-06-15T12:01:54+08:00">
                2019-06-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="ClickHouse-zk依赖优化"><a href="#ClickHouse-zk依赖优化" class="headerlink" title="ClickHouse zk依赖优化"></a>ClickHouse zk依赖优化</h1><p>ClickHouse 集群严重依赖zookeeper，clickhouse集群服务会在zk上存储大量的信息，例如数据库表metadata、blocksr、replicas等信息，znode节点和数据量/数据表呈线性相关。</p>
<p>ClickHouse把zk当做三种服务的结合，协调服务，日志服务、数据表catalog service。同时clickhouse在启动时还会对存在本地表的schema信息和存在zk上的schema信息做校验，如果两者存在差异则启动异常。</p>
<p>当前我们没有能力针对clickhouse做源码定制化，只能通过一些优化手段，让zk不至于成为整个系统的瓶颈。</p>
<p>第一原则是clickhouse依赖的zk不要和其他组件公用，其次是zk的各种参数调优。线上我们有个ClickHouse集群依赖的zk和其他组件公用，并且该zk还数据还存在机械盘上，严重影响到了ClickHouse集群的性能。ClickHouse从老的公用zookeeper中迁移到新的zookeeper的一些流程：</p>
<ol>
<li>新部署一个zookeeper组件，把zk组件的dataDir和dataLogDir存放固盘，如果条件允许的话这两个目录最好不要存放在同一个固盘;</li>
</ol>
<ol>
<li>从老Zookeeper中获取最新的snapshot，并且传输到新zookeeper中myid最大的三台机器上(假设zk节点为5);</li>
</ol>
<ol>
<li>增大新zookeeper的syncLimit和initLimit配置项，避免zookeeper在leader选举时同步snapshot超时，导致leader选举失败，因为clickhouse在zookeeper上创建的节点很多，并且snapshot文件挺大；</li>
</ol>
<ol>
<li>新zookeeper部署完成后，检测clickhouse在zk上的znode节点是否和老节点一致;</li>
</ol>
<ol>
<li><p>更改clickhouse配置文件中zk相关的设置，涉及到的主要配置文件:</p>
<blockquote>
<p>/etc/clickhouse-server/metrika.xml</p>
<p>/etc/clickhouse-server-wingman/metrika.xml</p>
<p>/etc/clickhouse-server/config-preprocessed.xml</p>
</blockquote>
</li>
</ol>
<ol>
<li>停止入库到clickhouse的程序，例如logkit、zabbix to clickhouse程序</li>
</ol>
<ol>
<li>停止clickhouse各个分片服务 <blockquote>
<p>service clickhouse-server stop</p>
<p>service clickhouse-server-wingman stop</p>
</blockquote>
</li>
</ol>
<p>其次是zookeeper参数调优，可以参考官方文档：</p>
<figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># http://hadoop.apache.org/zookeeper/docs/current/zookeeperAdmin.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The number of milliseconds of each tick</span></span><br><span class="line"><span class="attr">tickTime</span>=<span class="number">2000</span></span><br><span class="line"><span class="comment"># The number of ticks that the initial</span></span><br><span class="line"><span class="comment"># synchronization phase can take</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="number">30000</span></span><br><span class="line"><span class="comment"># The number of ticks that can pass between</span></span><br><span class="line"><span class="comment"># sending a request and getting an acknowledgement</span></span><br><span class="line"><span class="attr">syncLimit</span>=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="attr">maxClientCnxns</span>=<span class="number">2000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">maxSessionTimeout</span>=<span class="number">60000000</span></span><br><span class="line"><span class="comment"># the directory where the snapshot is stored.</span></span><br><span class="line"><span class="attr">dataDir</span>=/opt/zookeeper/&#123;&#123; cluster[<span class="string">'name'</span>] &#125;&#125;/data</span><br><span class="line"><span class="comment"># Place the dataLogDir to a separate physical disc for better performance</span></span><br><span class="line"><span class="attr">dataLogDir</span>=/opt/zookeeper/&#123;&#123; cluster[<span class="string">'name'</span>] &#125;&#125;/logs</span><br><span class="line"></span><br><span class="line">autopurge.snapRetainCount=10</span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># To avoid seeks ZooKeeper allocates space in the transaction log file in</span></span><br><span class="line"><span class="comment"># blocks of preAllocSize kilobytes. The default block size is 64M. One reason</span></span><br><span class="line"><span class="comment"># for changing the size of the blocks is to reduce the block size if snapshots</span></span><br><span class="line"><span class="comment"># are taken more often. (Also, see snapCount).</span></span><br><span class="line"><span class="attr">preAllocSize</span>=<span class="number">131072</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Clients can submit requests faster than ZooKeeper can process them,</span></span><br><span class="line"><span class="comment"># especially if there are a lot of clients. To prevent ZooKeeper from running</span></span><br><span class="line"><span class="comment"># out of memory due to queued requests, ZooKeeper will throttle clients so that</span></span><br><span class="line"><span class="comment"># there is no more than globalOutstandingLimit outstanding requests in the</span></span><br><span class="line"><span class="comment"># system. The default limit is 1,000.ZooKeeper logs transactions to a</span></span><br><span class="line"><span class="comment"># transaction log. After snapCount transactions are written to a log file a</span></span><br><span class="line"><span class="comment"># snapshot is started and a new transaction log file is started. The default</span></span><br><span class="line"><span class="comment"># snapCount is 10,000.</span></span><br><span class="line"><span class="attr">snapCount</span>=<span class="number">3000000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If this option is defined, requests will be will logged to a trace file named</span></span><br><span class="line"><span class="comment"># traceFile.year.month.day.</span></span><br><span class="line"><span class="comment">#traceFile=</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Leader accepts client connections. Default value is "yes". The leader machine</span></span><br><span class="line"><span class="comment"># coordinates updates. For higher update throughput at thes slight expense of</span></span><br><span class="line"><span class="comment"># read throughput the leader can be configured to not accept clients and focus</span></span><br><span class="line"><span class="comment"># on coordination.</span></span><br><span class="line"><span class="attr">leaderServes</span>=<span class="literal">yes</span></span><br><span class="line"></span><br><span class="line"><span class="attr">standaloneEnabled</span>=<span class="literal">false</span></span><br><span class="line"><span class="attr">dynamicConfigFile</span>=/etc/zookeeper-&#123;&#123; cluster[<span class="string">'name'</span>] &#125;&#125;/conf/zoo.cfg.dynamic</span><br></pre></td></tr></table></figure>
<p>Java虚拟机参数调优：</p>
<figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">NAME</span>=zookeeper-&#123;&#123; cluster[<span class="string">'name'</span>] &#125;&#125;</span><br><span class="line"><span class="attr">ZOOCFGDIR</span>=/etc/<span class="variable">$NAME</span>/conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO this is really ugly</span></span><br><span class="line"><span class="comment"># How to find out, which jars are needed?</span></span><br><span class="line"><span class="comment"># seems, that log4j requires the log4j.properties file to be in the classpath</span></span><br><span class="line"><span class="attr">CLASSPATH</span>=<span class="string">"$ZOOCFGDIR:/usr/build/classes:/usr/build/lib/*.jar:/usr/share/zookeeper/zookeeper-3.5.1-metrika.jar:/usr/share/zookeeper/slf4j-log4j12-1.7.5.jar:/usr/share/zookeeper/slf4j-api-1.7.5.jar:/usr/share/zookeeper/servlet-api-2.5-20081211.jar:/usr/share/zookeeper/netty-3.7.0.Final.jar:/usr/share/zookeeper/log4j-1.2.16.jar:/usr/share/zookeeper/jline-2.11.jar:/usr/share/zookeeper/jetty-util-6.1.26.jar:/usr/share/zookeeper/jetty-6.1.26.jar:/usr/share/zookeeper/javacc.jar:/usr/share/zookeeper/jackson-mapper-asl-1.9.11.jar:/usr/share/zookeeper/jackson-core-asl-1.9.11.jar:/usr/share/zookeeper/commons-cli-1.2.jar:/usr/src/java/lib/*.jar:/usr/etc/zookeeper"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ZOOCFG</span>=<span class="string">"$ZOOCFGDIR/zoo.cfg"</span></span><br><span class="line"><span class="attr">ZOO_LOG_DIR</span>=/var/log/<span class="variable">$NAME</span></span><br><span class="line"><span class="attr">USER</span>=zookeeper</span><br><span class="line"><span class="attr">GROUP</span>=zookeeper</span><br><span class="line"><span class="attr">PIDDIR</span>=/var/run/<span class="variable">$NAME</span></span><br><span class="line"><span class="attr">PIDFILE</span>=<span class="variable">$PIDDIR</span>/<span class="variable">$NAME</span>.pid</span><br><span class="line"><span class="attr">SCRIPTNAME</span>=/etc/init.d/<span class="variable">$NAME</span></span><br><span class="line"><span class="attr">JAVA</span>=/usr/bin/java</span><br><span class="line"><span class="attr">ZOOMAIN</span>=<span class="string">"org.apache.zookeeper.server.quorum.QuorumPeerMain"</span></span><br><span class="line"><span class="attr">ZOO_LOG4J_PROP</span>=<span class="string">"INFO,ROLLINGFILE"</span></span><br><span class="line"><span class="attr">JMXLOCALONLY</span>=<span class="literal">false</span></span><br><span class="line"><span class="attr">JAVA_OPTS</span>=<span class="string">"-Xms&#123;&#123; cluster.get('xms','128M') &#125;&#125; \</span></span><br><span class="line"><span class="string">    -Xmx&#123;&#123; cluster.get('xmx','1G') &#125;&#125; \</span></span><br><span class="line"><span class="string">    -Xloggc:/var/log/$NAME/zookeeper-gc.log \</span></span><br><span class="line"><span class="string">    -XX:+UseGCLogFileRotation \</span></span><br><span class="line"><span class="string">    -XX:NumberOfGCLogFiles=16 \</span></span><br><span class="line"><span class="string">    -XX:GCLogFileSize=16M \</span></span><br><span class="line"><span class="string">    -verbose:gc \</span></span><br><span class="line"><span class="string">    -XX:+PrintGCTimeStamps \</span></span><br><span class="line"><span class="string">    -XX:+PrintGCDateStamps \</span></span><br><span class="line"><span class="string">    -XX:+PrintGCDetails</span></span><br><span class="line"><span class="string">    -XX:+PrintTenuringDistribution \</span></span><br><span class="line"><span class="string">    -XX:+PrintGCApplicationStoppedTime \</span></span><br><span class="line"><span class="string">    -XX:+PrintGCApplicationConcurrentTime \</span></span><br><span class="line"><span class="string">    -XX:+PrintSafepointStatistics \</span></span><br><span class="line"><span class="string">    -XX:+UseParNewGC \</span></span><br><span class="line"><span class="string">    -XX:+UseConcMarkSweepGC \</span></span><br><span class="line"><span class="string">-XX:+CMSParallelRemarkEnabled"</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Yujie" />
          <p class="site-author-name" itemprop="name">Yujie</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yujie</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
